{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "    create_topology.py\n",
    "\n",
    "        Script to process raw node and edge data.\n",
    "\n",
    "        Workflow:\n",
    "            - Merge Multilinestrings from power line data       [Complete]\n",
    "            - Add junction nodes where lines split              [Complete]\n",
    "            - Add sink nodes to low voltage                     [Complete]\n",
    "            - Connect supply to substations                     [Complete]\n",
    "            - Connect high voltage grid to low voltage grid     [Complete]\n",
    "            - Create bi-directional grid                        [Complete]\n",
    "            - Save processed spatial data                       [Complete]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#=======================\n",
    "# Modules\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.wkt import loads\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Add local directory to path\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "# Import infrasim spatial tools\n",
    "from JEM.jem.spatial import get_isolated_graphs\n",
    "from JEM.jem.utils import get_nodal_edges\n",
    "\n",
    "# Import local copy of snkit\n",
    "from JEM.snkit.snkit.src.snkit.network import *\n",
    "\n",
    "# Import local functions\n",
    "from utils import *\n",
    "from merge_cost_data import *\n",
    "from electricity_demand_assignment import *\n",
    "from merge_elec_consumption_data import *\n",
    "\n",
    "#=======================\n",
    "# GLOBAL PARAMS\n",
    "\n",
    "verbose_flag=True\n",
    "remove_connected_components = True\n",
    "connected_component_tolerance = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================\n",
    "# PROCESSING\n",
    "\n",
    "# read data\n",
    "network = read_data()\n",
    "verbose_print('loaded data',flag=verbose_flag)\n",
    "\n",
    "# remove known bugs\n",
    "if 'bug' in network.edges.columns:\n",
    "    network.edges = network.edges[network.edges.bug != 'true'].reset_index(drop=True)\n",
    "verbose_print('removed known bugs',flag=verbose_flag)\n",
    "\n",
    "# merge multilinestrings\n",
    "network = remove_multiline(network)\n",
    "verbose_print('removed multilines',flag=verbose_flag)\n",
    "\n",
    "# delete NoneType\n",
    "network = remove_nontype(network)\n",
    "verbose_print('removed NonType',flag=verbose_flag)\n",
    "\n",
    "# explode multipart linestrings\n",
    "network = explode_multipart(network)\n",
    "verbose_print('explode multipart linestrings',flag=verbose_flag)\n",
    "\n",
    "# save raw data from jps\n",
    "jps_nodes = network.nodes.copy()\n",
    "jps_edges = network.edges.copy()\n",
    "\n",
    "# Merge edges\n",
    "network = add_endpoints(network)\n",
    "verbose_print('added end points',flag=verbose_flag)\n",
    "\n",
    "# add ids\n",
    "network = add_ids(network)\n",
    "verbose_print('added IDs',flag=verbose_flag)\n",
    "\n",
    "# add topology\n",
    "network = add_topology(network, id_col='id')\n",
    "verbose_print('added topology',flag=verbose_flag)\n",
    "\n",
    "# merge using snkit\n",
    "# network = merge_edges(network,by='asset_type')\n",
    "verbose_print('merged edges',flag=verbose_flag)\n",
    "\n",
    "# remove multilines again...\n",
    "network = remove_multiline(network)\n",
    "\n",
    "#===\n",
    "# SNAP LV LINES TO SUBSTATIONS\n",
    "\n",
    "verbose_print('snapping lines to substations...',flag=verbose_flag)\n",
    "\n",
    "# LV\n",
    "lv_voltages = ['24 kV', '12 kV']\n",
    "# get substations\n",
    "substations = network.nodes[network.nodes.subtype == 'substation'].geometry\n",
    "# loop\n",
    "for s in substations:\n",
    "    # index edges\n",
    "    idx_edges = edges_within(s,\n",
    "                             network.edges[network.edges.voltage.isin(lv_voltages)],\n",
    "                             distance=40)\n",
    "    # snap\n",
    "    for e in idx_edges.itertuples():\n",
    "        # get current coords of edge\n",
    "        e_coords = list(e.geometry.coords)\n",
    "        # get coords of point\n",
    "        s_coords = list(s.coords)\n",
    "        # modify first coord of edge to be coord of point (i.e. snap)\n",
    "        e_coords[0] = s_coords[0]\n",
    "        # update in edge data\n",
    "        network.edges.loc[network.edges.index == e.Index, 'geometry'] = LineString(e_coords)\n",
    "\n",
    "verbose_print('done',flag=verbose_flag)\n",
    "\n",
    "\n",
    "\n",
    "#===\n",
    "# ADD JUNCTIONS AND SINKS\n",
    "\n",
    "verbose_print('adding junctions and sinks...',flag=verbose_flag)\n",
    "\n",
    "# add endpoints\n",
    "network = add_endpoints(network)\n",
    "# update asset_type\n",
    "network.nodes.loc[~network.nodes.subtype.isin(['sink','junction','sink']),'subtype'] = 'pole'\n",
    "network.nodes.loc[~network.nodes.asset_type.isin(['sink','junction','sink']),'asset_type'] = 'junction'\n",
    "# split edges between nodes\n",
    "network = split_edges_at_nodes(network)\n",
    "# add ids\n",
    "network = update_notation(network)\n",
    "## network.edges.drop(['id','from_id','to_id'],axis=1)\n",
    "## network = add_id_to_nodes(network)\n",
    "## network = add_edge_notation(network)\n",
    "# find true sink nodes\n",
    "sinks = list(network.edges.to_id.unique())\n",
    "starts = list(network.edges.from_id.unique())\n",
    "true_sinks = []\n",
    "for s in sinks:\n",
    "    if s in starts:\n",
    "        continue\n",
    "    else:\n",
    "        true_sinks.append(s)\n",
    "\n",
    "# update true sinks\n",
    "network.nodes.loc[network.nodes.id.isin(true_sinks),'asset_type'] = 'sink'\n",
    "network.nodes.loc[network.nodes.id.isin(true_sinks),'subtype'] = 'demand'\n",
    "\n",
    "# remap asset_type and asset_type from original data\n",
    "for n in jps_nodes.title:\n",
    "    network.nodes.loc[network.nodes.title == n, 'asset_type'] = jps_nodes.loc[jps_nodes.title == n].asset_type.iloc[0]\n",
    "    network.nodes.loc[network.nodes.title == n, 'subtype'] = jps_nodes.loc[jps_nodes.title == n].subtype.iloc[0]\n",
    "\n",
    "verbose_print('done',flag=verbose_flag)\n",
    "\n",
    "\n",
    "\n",
    "#===\n",
    "# CONVERT FALSE JUNCTIONS TO SINKS\n",
    "\n",
    "verbose_print('converting false junctions...',flag=verbose_flag)\n",
    "\n",
    "nodes_to_test = network.nodes[network.nodes.subtype.isin(['pole'])].reset_index(drop=True)\n",
    "for n in nodes_to_test.id:\n",
    "#for n in ['node_1694']:\n",
    "    degree = node_connectivity_degree(node=n, network=network)\n",
    "    if degree == 1:\n",
    "        # change node asset_type\n",
    "        network.nodes.loc[network.nodes.id == n, 'asset_type'] = 'sink'\n",
    "        network.nodes.loc[network.nodes.id == n, 'subtype'] = 'demand'\n",
    "        # reverse arc direction\n",
    "        prev_line = network.edges[network.edges.from_id == n].geometry.values[0]\n",
    "        network.edges.loc[network.edges.from_id == n, 'geometry'] = flip(prev_line)\n",
    "\n",
    "verbose_print('done',flag=verbose_flag)\n",
    "\n",
    "\n",
    "\n",
    "#===\n",
    "# CLEANING/FORMATTING\n",
    "\n",
    "# add length to line data\n",
    "network = add_edge_length(network)\n",
    "verbose_print('added line lengths',flag=verbose_flag)\n",
    "\n",
    "# remove duplicated\n",
    "network = remove_duplicates(network)\n",
    "verbose_print('removed duplicates',flag=verbose_flag)\n",
    "\n",
    "# change voltage column format\n",
    "network.edges['voltage_kV'] = network.edges.voltage.str.replace('kV','').astype('int')\n",
    "\n",
    "# add max/min\n",
    "network = add_limits_to_edges(network)\n",
    "verbose_print('added limits to edge flows',flag=verbose_flag)\n",
    "\n",
    "# double-up edges\n",
    "network = bidirectional_edges(network)\n",
    "verbose_print('made edges bidirectional',flag=verbose_flag)\n",
    "\n",
    "# remove sink-to-sink connections\n",
    "network = remove_sink_to_sink(network)\n",
    "verbose_print('removed sink to sinks',flag=verbose_flag)\n",
    "\n",
    "# add node degree\n",
    "network = add_nodal_degree(network)\n",
    "verbose_print('added nodal degrees',flag=verbose_flag)\n",
    "\n",
    "# drop zero degree sinks\n",
    "network = remove_stranded_nodes(network)\n",
    "verbose_print('removed stranded nodes',flag=verbose_flag)\n",
    "\n",
    "# remove self-loops\n",
    "network = remove_self_loops(network)\n",
    "verbose_print('removed self-loops',flag=verbose_flag)\n",
    "\n",
    "# change asset_type of sinks with >2 degree connectivity\n",
    "network.nodes.loc[(network.nodes.degree > 2) & \\\n",
    "                  (network.nodes.asset_type == 'sink'), 'asset_type'] = 'junction'\n",
    "\n",
    "verbose_print('converted sinks of degree>0 to junctions',flag=verbose_flag)\n",
    "\n",
    "\n",
    "\n",
    "#===\n",
    "# ADD COST DATA\n",
    "verbose_print('merging cost data...',flag=verbose_flag)\n",
    "\n",
    "network = merge_cost_data(network,\n",
    "                        path_to_costs='../data/costs_and_damages/maximum_damage_values.csv',\n",
    "                        print_to_console=False)\n",
    "\n",
    "verbose_print('done',flag=verbose_flag)\n",
    "\n",
    "\n",
    "\n",
    "#===\n",
    "# ADD POPULATION\n",
    "verbose_print('adding population...',flag=verbose_flag)\n",
    "population = gpd.read_file('../data/population-russell/population.gpkg')\n",
    "network = assign_pop_to_sinks(network,population)\n",
    "verbose_print('done',flag=verbose_flag)\n",
    "\n",
    "\n",
    "#===\n",
    "# APPEND ELECTRICITY INTENSITIES\n",
    "network = append_electricity_intensities(network)\n",
    "verbose_print('appended electricity data',flag=verbose_flag)\n",
    "\n",
    "\n",
    "#===\n",
    "# GET CONNECTED COMPONENTS\n",
    "verbose_print('getting connected components...',flag=verbose_flag)\n",
    "\n",
    "network = add_component_ids(network)\n",
    "# remove\n",
    "if not remove_connected_components:\n",
    "    pass\n",
    "else:\n",
    "    graphs_to_remove = network.edges.loc[network.edges.component_id > connected_component_tolerance]\n",
    "    nodes_to_remove = graphs_to_remove.from_id.to_list() + graphs_to_remove.to_id.to_list()\n",
    "    edges_to_remove = graphs_to_remove.id.to_list()\n",
    "    # drop\n",
    "    network.nodes = network.nodes.loc[~network.nodes.id.isin(nodes_to_remove)].reset_index(drop=True)\n",
    "    network.edges = network.edges.loc[~network.edges.id.isin(edges_to_remove)].reset_index(drop=True)\n",
    "# Update network notation\n",
    "network = update_notation(network)\n",
    "\n",
    "verbose_print('done',flag=verbose_flag)\n",
    "\n",
    "\n",
    "#===\n",
    "# ADD CAPACITY ATTRIBUTES\n",
    "verbose_print('adding capacity attributes to nodes...',flag=verbose_flag)\n",
    "\n",
    "def nodal_capacity_from_edges(node,network):\n",
    "    nodal_edges = get_nodal_edges(network,node).id.to_list()\n",
    "    return network.edges.loc[network.edges.id.isin(nodal_edges)]['max'].max()\n",
    "\n",
    "\n",
    "network.nodes['capacity'] \\\n",
    "    = network.nodes.progress_apply(\n",
    "        lambda x: nodal_capacity_from_edges(x['id'],network) \\\n",
    "            if pd.isnull(x['capacity']) else x['capacity'], axis=1 )\n",
    "\n",
    "verbose_print('done',flag=verbose_flag)\n",
    "\n",
    "\n",
    "#===\n",
    "# ADD TOTAL COSTS\n",
    "\n",
    "# edges\n",
    "network.edges['cost_min'] = network.edges['uc_min'] * network.edges['max'] * network.edges['length']\n",
    "network.edges['cost_max'] = network.edges['uc_max'] * network.edges['max'] * network.edges['length']\n",
    "network.edges['cost_avg'] = network.edges['uc_avg'] * network.edges['max'] * network.edges['length']\n",
    "network.edges['cost_uom'] = '$US'\n",
    "\n",
    "# nodes\n",
    "network.nodes['cost_min'] = network.nodes['uc_min'] * network.nodes['capacity']\n",
    "network.nodes['cost_max'] = network.nodes['uc_max'] * network.nodes['capacity']\n",
    "network.nodes['cost_avg'] = network.nodes['uc_avg'] * network.nodes['capacity']\n",
    "network.nodes['cost_uom'] = '$US'\n",
    "\n",
    "\n",
    "#===\n",
    "# REINDEX\n",
    "network.edges = network.edges[['id', 'asset_type', 'from_id', 'to_id', 'from_type', 'to_type',\n",
    "                               'voltage_kV', 'losses', 'length', 'min', 'max', \n",
    "                               'uc_min','uc_max', 'uc_avg','uc_uom',\n",
    "                               'cost_min','cost_max', 'cost_avg','cost_uom',\n",
    "                               'name', 'parish','source', 'component_id', 'geometry']]\n",
    "\n",
    "network.nodes = network.nodes[['id','asset_type','subtype','capacity','population',\n",
    "                              'uc_min','uc_max','uc_avg','uc_uom',\n",
    "                              'cost_min','cost_max', 'cost_avg','cost_uom',\n",
    "                              'ei', 'ei_uom','degree','parish','title','source','geometry']]\n",
    "\n",
    "verbose_print('re-indexed data',flag=verbose_flag)\n",
    "\n",
    "#===\n",
    "# SAVE DATA\n",
    "verbose_print('saving...',flag=verbose_flag)\n",
    "\n",
    "save_data(network)\n",
    "\n",
    "verbose_print('create_toplogy finished',flag=verbose_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===\n",
    "# ADD POPULATION\n",
    "verbose_print('adding population...',flag=verbose_flag)\n",
    "population = gpd.read_file('../data/population-russell/population.gpkg')\n",
    "network = assign_pop_to_sinks(network,population)\n",
    "verbose_print('done',flag=verbose_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD POPULATION\n",
    "population_dataframe = gpd.read_file('../data/population-russell/population.gpkg')\n",
    "# get sinks\n",
    "sinks = network.nodes[network.nodes['asset_type'] == 'sink']\n",
    "# change crs\n",
    "epsg=3448,\n",
    "node_id_column='id'\n",
    "population_value_column='population'\n",
    "nodes_dataframe = sinks.copy()\n",
    "#sinks = sinks.to_crs(epsg=epsg)\n",
    "#pop_bound = pop_bound.to_crs(epsg=epsg)\n",
    "\n",
    "#------\n",
    "# assign_node_weights_by_population_proximity\n",
    "\n",
    "# load provinces and get geometry of the right population_dataframe\n",
    "sindex_population_dataframe = population_dataframe.sindex\n",
    "\n",
    "# create Voronoi polygons for the nodes\n",
    "xy_list = []\n",
    "for iter_, values in nodes_dataframe.iterrows():\n",
    "    xy = list(values.geometry.coords)\n",
    "    xy_list += [list(xy[0])]\n",
    "\n",
    "vor = Voronoi(np.array(xy_list))\n",
    "regions, vertices = voronoi_finite_polygons_2d(vor)\n",
    "min_x = vor.min_bound[0] - 0.1\n",
    "max_x = vor.max_bound[0] + 0.1\n",
    "min_y = vor.min_bound[1] - 0.1\n",
    "max_y = vor.max_bound[1] + 0.1\n",
    "\n",
    "mins = np.tile((min_x, min_y), (vertices.shape[0], 1))\n",
    "bounded_vertices = np.max((vertices, mins), axis=0)\n",
    "maxs = np.tile((max_x, max_y), (vertices.shape[0], 1))\n",
    "bounded_vertices = np.min((bounded_vertices, maxs), axis=0)\n",
    "\n",
    "box = Polygon([[min_x, min_y], [min_x, max_y], [max_x, max_y], [max_x, min_y]])\n",
    "\n",
    "poly_list = []\n",
    "for region in regions:\n",
    "    polygon = vertices[region]\n",
    "    # Clipping polygon\n",
    "    poly = Polygon(polygon)\n",
    "    poly = poly.intersection(box)\n",
    "    poly_list.append(poly)\n",
    "\n",
    "poly_index = list(np.arange(0, len(poly_list), 1))\n",
    "poly_df = pd.DataFrame(list(zip(poly_index, poly_list)),\n",
    "                               columns=['gid', 'geometry'])\n",
    "\n",
    "gdf_voronoi = gpd.GeoDataFrame(poly_df, geometry = 'geometry') #,crs=f'epsg:{epsg}'\n",
    "\n",
    "gdf_voronoi['areas'] = gdf_voronoi.geometry.area #gdf_voronoi.progress_apply(lambda x:x.geometry.area,axis=1)\n",
    "\n",
    "gdf_voronoi = gdf_voronoi.head(100)\n",
    "\n",
    "def extract_nodes_within_gdf(x,nodes_dataframe,node_id_column):\n",
    "    a = nodes_dataframe.loc[ list(nodes_dataframe.geometry.within(x)) ]\n",
    "    if len(a.index) > 0:\n",
    "        v = a[node_id_column].values[0]\n",
    "    else:\n",
    "        v = np.nan\n",
    "    return v\n",
    "\n",
    "gdf_voronoi[node_id_column] = gdf_voronoi.progress_apply(\n",
    "        lambda row: extract_nodes_within_gdf(row['geometry'],nodes_dataframe,node_id_column),axis=1)\n",
    "\n",
    "gdf_voronoi[population_value_column] = 0\n",
    "gdf_voronoi = assign_value_in_area_proportions(population_dataframe, gdf_voronoi, population_value_column)\n",
    "gdf_voronoi = gdf_voronoi[~(gdf_voronoi[node_id_column] == '')]\n",
    "\n",
    "gdf_pops = gdf_voronoi#[[node_id_column, population_value_column]]\n",
    "del gdf_voronoi, poly_list, poly_df\n",
    "\n",
    "nodes_dataframe = pd.merge(nodes_dataframe, gdf_pops, how='left', on=[node_id_column])\n",
    "del gdf_pops, population_dataframe\n",
    "\n",
    "new_nodes = nodes_dataframe\n",
    "\n",
    "pop_mapped = new_nodes[['id','population']].set_index('id')['population'].to_dict()\n",
    "# reassign\n",
    "network.nodes['population'] = network.nodes['id'].map(pop_mapped).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from scipy.spatial import Voronoi\n",
    "from shapely.geometry import Polygon, shape\n",
    "# workaround for geopandas >0.9 until snkit #37 and geopandas #1977 are fixed\n",
    "gpd._compat.USE_PYGEOS = False\n",
    "import fiona\n",
    "import numpy as np\n",
    "import snkit\n",
    "#import snkit_network\n",
    "from tqdm import tqdm\n",
    "#tqdm.pandas()\n",
    "\n",
    "def assign_pop_to_sinks(network,pop_bound,\n",
    "                        epsg=3448,nodal_id='id',pop_id='population'):\n",
    "    '''Assign population to sink nodes\n",
    "    '''\n",
    "    # get sinks\n",
    "    sinks = network.nodes[network.nodes['asset_type'] == 'sink']\n",
    "    # change crs\n",
    "    sinks = sinks.to_crs(epsg=epsg)\n",
    "    pop_bound = pop_bound.to_crs(epsg=3448)\n",
    "    # compute\n",
    "    new_nodes = assign_node_weights_by_population_proximity(sinks,\n",
    "                                                            pop_bound,\n",
    "                                                            nodal_id,\n",
    "                                                            pop_id,\n",
    "                                                            epsg=epsg,\n",
    "                                                            save=True,\n",
    "                                                            voronoi_path='../data/spatial/electricity_voronoi.shp',\n",
    "                                                            )\n",
    "    #remap\n",
    "    pop_mapped = new_nodes[['id','population']].set_index('id')['population'].to_dict()\n",
    "    # reassign\n",
    "    network.nodes['population'] = network.nodes['id'].map(pop_mapped).fillna(0)\n",
    "    return network\n",
    "\n",
    "\n",
    "def assign_node_weights_by_population_proximity(nodes_dataframe,\n",
    "                        population_dataframe,\n",
    "                        node_id_column,population_value_column,epsg=4326,**kwargs):\n",
    "    \"\"\"Assign weights to nodes based on their nearest populations\n",
    "\n",
    "        - By finding the population that intersect with the Voronoi extents of nodes\n",
    "\n",
    "    Parameters\n",
    "        - nodes_dataframe - Geodataframe of the nodes\n",
    "        - population_dataframe - Geodataframe of the population\n",
    "        - nodes_id_column - String name of node ID column\n",
    "        - population_value_column - String name of column containing population values\n",
    "\n",
    "    Outputs\n",
    "        - nodes - Geopandas dataframe of nodes with new column called population\n",
    "    \"\"\"\n",
    "\n",
    "    # load provinces and get geometry of the right population_dataframe\n",
    "    sindex_population_dataframe = population_dataframe.sindex\n",
    "\n",
    "    # create Voronoi polygons for the nodes\n",
    "    xy_list = []\n",
    "    for iter_, values in nodes_dataframe.iterrows():\n",
    "        xy = list(values.geometry.coords)\n",
    "        xy_list += [list(xy[0])]\n",
    "\n",
    "    vor = Voronoi(np.array(xy_list))\n",
    "    regions, vertices = voronoi_finite_polygons_2d(vor)\n",
    "    min_x = vor.min_bound[0] - 0.1\n",
    "    max_x = vor.max_bound[0] + 0.1\n",
    "    min_y = vor.min_bound[1] - 0.1\n",
    "    max_y = vor.max_bound[1] + 0.1\n",
    "\n",
    "    mins = np.tile((min_x, min_y), (vertices.shape[0], 1))\n",
    "    bounded_vertices = np.max((vertices, mins), axis=0)\n",
    "    maxs = np.tile((max_x, max_y), (vertices.shape[0], 1))\n",
    "    bounded_vertices = np.min((bounded_vertices, maxs), axis=0)\n",
    "\n",
    "    box = Polygon([[min_x, min_y], [min_x, max_y], [max_x, max_y], [max_x, min_y]])\n",
    "\n",
    "    poly_list = []\n",
    "    for region in regions:\n",
    "        polygon = vertices[region]\n",
    "        # Clipping polygon\n",
    "        poly = Polygon(polygon)\n",
    "        poly = poly.intersection(box)\n",
    "        poly_list.append(poly)\n",
    "\n",
    "    poly_index = list(np.arange(0, len(poly_list), 1))\n",
    "    poly_df = pd.DataFrame(list(zip(poly_index, poly_list)),\n",
    "                                   columns=['gid', 'geometry'])\n",
    "    \n",
    "    gdf_voronoi = gpd.GeoDataFrame(poly_df, geometry = 'geometry',crs=f'epsg:{epsg}')    \n",
    "    gdf_voronoi['areas'] = gdf_voronoi.progress_apply(lambda x:x.geometry.area,axis=1)\n",
    "    gdf_voronoi[node_id_column] = gdf_voronoi.progress_apply(\n",
    "        lambda x: extract_nodes_within_gdf(x, nodes_dataframe, node_id_column), axis=1)\n",
    "    if not kwargs.get('save',False):\n",
    "        pass\n",
    "    else:\n",
    "        gdf_voronoi.to_file(kwargs.get('voronoi_path','voronoi-output.shp'))\n",
    "\n",
    "    gdf_voronoi[population_value_column] = 0\n",
    "    gdf_voronoi = assign_value_in_area_proportions(population_dataframe, gdf_voronoi, population_value_column)\n",
    "    gdf_voronoi = gdf_voronoi[~(gdf_voronoi[node_id_column] == '')]\n",
    "\n",
    "    gdf_pops = gdf_voronoi#[[node_id_column, population_value_column]]\n",
    "    del gdf_voronoi, poly_list, poly_df\n",
    "\n",
    "    nodes_dataframe = pd.merge(nodes_dataframe, gdf_pops, how='left', on=[node_id_column])\n",
    "    del gdf_pops, population_dataframe\n",
    "\n",
    "    return nodes_dataframe\n",
    "\n",
    "\n",
    "def voronoi_finite_polygons_2d(vor, radius=None):\n",
    "    \"\"\"Reconstruct infinite voronoi regions in a 2D diagram to finite regions.\n",
    "\n",
    "    Source: https://stackoverflow.com/questions/36063533/clipping-a-voronoi-diagram-python\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vor : Voronoi\n",
    "        Input diagram\n",
    "    radius : float, optional\n",
    "        Distance to 'points at infinity'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    regions : list of tuples\n",
    "        Indices of vertices in each revised Voronoi regions.\n",
    "    vertices : list of tuples\n",
    "        Coordinates for revised Voronoi vertices. Same as coordinates\n",
    "        of input vertices, with 'points at infinity' appended to the\n",
    "        end\n",
    "    \"\"\"\n",
    "\n",
    "    if vor.points.shape[1] != 2:\n",
    "        raise ValueError(\"Requires 2D input\")\n",
    "\n",
    "    new_regions = []\n",
    "    new_vertices = vor.vertices.tolist()\n",
    "\n",
    "    center = vor.points.mean(axis=0)\n",
    "    if radius is None:\n",
    "        radius = vor.points.ptp().max()*2\n",
    "\n",
    "    # Construct a map containing all ridges for a given point\n",
    "    all_ridges = {}\n",
    "    for (p1, p2), (v1, v2) in zip(vor.ridge_points, vor.ridge_vertices):\n",
    "        all_ridges.setdefault(p1, []).append((p2, v1, v2))\n",
    "        all_ridges.setdefault(p2, []).append((p1, v1, v2))\n",
    "\n",
    "    # Reconstruct infinite regions\n",
    "    for p1, region in enumerate(vor.point_region):\n",
    "        vertices = vor.regions[region]\n",
    "\n",
    "        if all(v >= 0 for v in vertices):\n",
    "            # finite region\n",
    "            new_regions.append(vertices)\n",
    "            continue\n",
    "\n",
    "        # reconstruct a non-finite region\n",
    "        ridges = all_ridges[p1]\n",
    "        new_region = [v for v in vertices if v >= 0]\n",
    "\n",
    "        for p2, v1, v2 in ridges:\n",
    "            if v2 < 0:\n",
    "                v1, v2 = v2, v1\n",
    "            if v1 >= 0:\n",
    "                # finite ridge: already in the region\n",
    "                continue\n",
    "\n",
    "            # Compute the missing endpoint of an infinite ridge\n",
    "\n",
    "            t = vor.points[p2] - vor.points[p1]  # tangent\n",
    "            t /= np.linalg.norm(t)\n",
    "            n = np.array([-t[1], t[0]])  # normal\n",
    "\n",
    "            midpoint = vor.points[[p1, p2]].mean(axis=0)\n",
    "            direction = np.sign(np.dot(midpoint - center, n)) * n\n",
    "            far_point = vor.vertices[v2] + direction * radius\n",
    "\n",
    "            new_region.append(len(new_vertices))\n",
    "            new_vertices.append(far_point.tolist())\n",
    "\n",
    "        # sort region counterclockwise\n",
    "        vs = np.asarray([new_vertices[v] for v in new_region])\n",
    "        c = vs.mean(axis=0)\n",
    "        angles = np.arctan2(vs[:, 1] - c[1], vs[:, 0] - c[0])\n",
    "        new_region = np.array(new_region)[np.argsort(angles)]\n",
    "\n",
    "        # finish\n",
    "        new_regions.append(new_region.tolist())\n",
    "\n",
    "    return new_regions, np.asarray(new_vertices)\n",
    "\n",
    "def assign_value_in_area_proportions(poly_1_gpd, poly_2_gpd, poly_attribute):\n",
    "    poly_1_sindex = poly_1_gpd.sindex\n",
    "    for p_2_index, polys_2 in poly_2_gpd.iterrows():\n",
    "        poly2_attr = 0\n",
    "        intersected_polys = poly_1_gpd.iloc[list(\n",
    "            poly_1_sindex.intersection(polys_2.geometry.bounds))]\n",
    "        for p_1_index, polys_1 in intersected_polys.iterrows():\n",
    "            if (polys_2['geometry'].intersects(polys_1['geometry']) is True) and (polys_1.geometry.is_valid is True) and (polys_2.geometry.is_valid is True):\n",
    "                poly2_attr += polys_1[poly_attribute]*polys_2['geometry'].intersection(\n",
    "                    polys_1['geometry']).area/polys_1['geometry'].area\n",
    "\n",
    "        poly_2_gpd.loc[p_2_index, poly_attribute] = poly2_attr\n",
    "\n",
    "    return poly_2_gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nodes_within_gdf2(input_df,input_nodes,column_name):\n",
    "    for x in tqdm(input_df.geometry):\n",
    "        a = input_nodes.loc[list(input_nodes.geometry.within(x))]\n",
    "        if len(a.index) > 0:\n",
    "            v = a[column_name].values[0]\n",
    "        else:\n",
    "            v = np.nan\n",
    "        input_df.loc[input_df.geometry == x,column_name] = v\n",
    "    return input_df\n",
    "\n",
    "\n",
    "gdf_voronoi = extract_nodes_within_gdf2(gdf_voronoi,nodes_dataframe,node_id_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nodes_within_gdf(x,nodes_dataframe,node_id_column):\n",
    "    a = nodes_dataframe.loc[ list(nodes_dataframe.geometry.within(x)) ]\n",
    "    if len(a.index) > 0:\n",
    "        v = a[column_name].values[0]\n",
    "    else:\n",
    "        v = np.nan\n",
    "    return v\n",
    "\n",
    "gdf_voronoi['node_id'] = \n",
    "    gdf_voronoi.progress_apply(\n",
    "        lambda row: extract_nodes_within_gdf(row['geometry'],nodes_dataframe,node_id_column),axis=1)\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
